---
title: "scrooge-paper"
author: "Dan Ovando"
date: "3/7/2018"
output: bookdown::html_document2
linkcolor: blue
bibliography: dissertation.bib
biblio-style: apalike
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r}
library(hrbrthemes)
library(extrafont)
library(scales)
library(rstan)
library(tidyverse)
library(wesanderson)
library(patchwork)
extrafont::loadfonts()
rstan::rstan_options(auto_write = TRUE)
  functions <- list.files(here::here("functions"))

  walk(functions, ~ here::here("functions", .x) %>% source()) # load local functions


  scrooge_theme <- theme_ipsum(base_size = 14, axis_title_size = 18)

  theme_set(scrooge_theme)

load(here::here("processed_data","fisheries_sandbox.Rdata"))

# load(here::here("presentations","gaines-lab.Rdata"))

  functions <- list.files(here::here("functions"))

  walk(functions, ~ here::here("functions", .x) %>% source()) # load local functions

  in_clouds <-  F

  run_name <- "v3.0"
  
    scrooge_theme <- theme_ipsum(base_size = 16, axis_title_size = 18, strip_text_size = 18)

  theme_set(scrooge_theme)


```


# Introduction


## General fisheries stuff


Effective fisheries management requires that managers and stakeholders have some ability to estimate and react to the abundance of fish in the ocean. The history of fisheries science is largely concerned with developing and improving our ability to accomplish this difficult task, starting from early models of growth overfishing [citation] and leading up to multi-species bio-geo-economic models[e.g. citation some mice model].  While the field has made dramatic advances in our ability to assess fisheries, by and large we have found two solutions to this problem: Fit highly complex integrated statistical models to diverse data streams [cite fancy stock assessment technique], or utilize increasing levels of statistical wizardry to try and squeeze more information out of limited data [what has lately been termed Data Limited Stock Assessments, or DLAs; cite]. The explosion of DLAs has been both promising and concerning. The majority of fisheries in the world lack the resources for fully integrated stock assessments, and so depend on this world of "data limited stock assessment". While there has been tremendous growth in this field, nearly all DLAs rely on the same streams of information that would have been available to a fisheries scientist in the 1800s: lengths [cite], captures [cite], and catch per unit effort[cite].

## DLAs

what they are, how do they usually work

@Dowling2014, @Dowling2015, @Dowling2016, @Carruthers2014, and @Prince2003

## Why integrate economic data?

[@Gordon1954; @Szuwalski; @Thorson2013a]

  - Neilsen 2017 (@Nielsen2017) is that lit review of coupled ecological-economic models. Ah right, these are all MSE style models though, not assessment modules. So, a good reference for ways to model effort dynamics, but not redundant on the effort dynamics. 

  - [@Branch2006] fleet dynamics and management. Right, this thinks about the way that fleet dynamics interact with different kinds of management. Interesting insights on how you want to include this into DLAs, but not much in the direct sense of integration to stock assessment
  
  - [@Salas2004] is similar but focuses on small scale fisheries. Interesting stuff but not much on the modeling front. But lots of good content thinking about behavioral dynamics of small scale fisheries that would be valuable to dive into. 
  
-[@vanPutten2012] theories and behavioral drivers underlying fleet dynamics. See @Vermard2008 for some modeling examples. Has lots of useful references in here. Random utility models for individual behavior. Basically, has a nice summary of sources for different ways to model and think about behavior. So, you can start with the profit maximizing side of things, but expand that out for different types of fleet dynamics. 

- @Fulton2011 human behavior: the key source of uncertainty. Objectives and uncertainty drive consequences, good source for thinking about this broad problem. 

- @Marchal2013 added value of fleet dynamics in models. This one looks at MSE style problems again, but has aome interesting fleet model specifications that you could steal. Equation 11 is handy, just more justification for change is the effort last year times some factor and profits over the last few years 

- @Clark1990 

- @Hoff2008

general intro to economic dynamics

availability of economic data

separation of recruitment from F

## Why Bayes?

A general argument for informative priors in data limited assessment

statistical rethinking, 

@McElreath2016

@Hobbs2015

@Thorson2017a

@Jiao2011

@Monnahan2016

@Karnauskas2011

@Myers2002

@McAllister1998

@Punt1997 (IMPORTANT TO INCLUDE)

## Research statement

This paper explores the ability of informative Bayesian priors built off of economic histories to improve data-limited stock assessment. 

# Methods

## Overview

Utilize SPASM to simulate true states of the world

Fit alternative models

scrooge-lite

scrooge

LIME

LBSPR

compare fit and bias

## SPASM

explanation of the model itself @Ovando2016, age structured model, sampling length comps, fleet models, error

## Other assessments

Explanation of 

@Rudd2017

@Hordyk2014

## SCROOGE

concept, likelihood, options, etc. 

economic shock explanation and illustration

# Results


## Case Studies

Focus on performance using economic priors and LIME priors; more cohesive than also then trying to compare to LIME/LBSPR. 

Save that for the mega-run, where you can then say something about when different models are likely to perform well, by predicting RMSE as a function of model with effects for each model scenario. 

For the case studies, the point is to highlight the general performance of the model. So, let's hold fishery constant, but now run the assessments no economic prior, and then with all incentive, all effort, and equal weighting, and compare performance

So you're running this here now, wouldn't this potentially be easier just to pull from your bank of saved runs? i.e. find the experiment numbers that match those, and pull in the assessment results? Though of course that gets tricky since it depends on having all of those saved and ready to go, doesn't allow for easy modification, so if this doesn't take that long I kind of like re-running it on the fly as long as runtime isn't too prohibitive. 

```{r case-studies}

case_studies <- purrr::cross_df(list(scenario = c("simple","complex"), 
                                     economic_model = c(1,0),
                                    effort_data_weight = c(0,0.5,1))) %>% 
  filter(!(economic_model == 0 & effort_data_weight > 0))


simple <- fisheries_sandbox %>% 
  filter(sci_name == "Lutjanus campechanus",
         steepness == 0.6, 
         sigma_r == min(sigma_r),
         sigma_effort == min(sigma_effort),
         price_cv == min(price_cv),
         cost_cv == min(cost_cv),
         q_cv == min(q_cv),
         q_ac == min(q_ac),
         obs_error == min(obs_error),
         fleet_model == "constant-effort") %>% 
  mutate(scenario = "simple")


complex <- fisheries_sandbox %>% 
  filter(sci_name == "Lutjanus campechanus",
         steepness == 0.9, 
         sigma_r == max(sigma_r),
         sigma_effort == max(sigma_effort),
         price_cv == max(price_cv),
         cost_cv == max(cost_cv),
         q_cv == max(q_cv),
         q_ac == max(q_ac),
         obs_error == min(obs_error),
         fleet_model == "open-access") %>% 
  mutate(scenario = "complex")

temp_studies <- 

case_studies <- case_studies %>% 
  left_join(simple %>% bind_rows(complex) %>% nest(-scenario), by = "scenario")
  
  
case_studies <- case_studies %>%
  mutate(assessment = pmap(
  list(
  fishery = data,
  experiment = scenario,
  economic_model = economic_model,
  effort_data_weight = effort_data_weight
  ),
  run_and_judge_scrooge
  ))

case_studies$assessment[[1]]$scrooge_performance[[1]]$comparison_plot + 
  lims(x = c(40,65))
  

case_studies$assessment[[2]]$scrooge_rec_performance[[1]]$comparison_plot +
  lims(x = c(40, 65))
  

case_studies$assessment[[2]]$scrooge_fit[[1]] %>% rstanarm::launch_shinystan()



case_studies <- case_studies %>% 
  mutate(f_t_hat = map(assessment, ~map_df(.x$processed_scrooge,"f_t")))



case_studies <- case_studies %>% 
  mutate(f_t = map(data, ~ map_df(.x$prepped_fishery,"simed_fishery") %>% 
                     group_by(year) %>% summarise(f = unique(f))))


true_f <- case_studies %>% 
  select(scenario, f_t) %>% 
  unique() %>% 
  unnest()
  

f_performance <- case_studies %>%
  select(-data, -assessment,-f_t) %>%
  unnest() %>%
  mutate(effort_data_weight = if_else(economic_model == 0, 99, effort_data_weight)) %>% mutate(effort_data_weight = factor(effort_data_weight))

f_summary <- f_performance %>%
  group_by(effort_data_weight, scenario, year) %>%
  summarise(
  lower = quantile(value, 0.1),
  upper = quantile(value, 0.9),
  mean_f = mean(value),
  median_f = median(value)
  ) %>%
  ungroup() %>% 
  mutate(effort_data_weight = factor(effort_data_weight))


f_performance_plot <- f_summary %>%
  ggplot()  +
  geom_ribbon(aes(
  year,
  ymin = lower,
  ymax = upper,
  fill = effort_data_weight
  ),
  alpha = 0.25) +
  geom_line(aes(year, mean_f, color =effort_data_weight )) +
  geom_line(data = true_f %>% filter(year %in% unique(f_performance$year)), aes(year, f)) +
  facet_wrap(~ scenario)
  

f_rmse_bias <- f_performance %>%
  left_join(true_f, by = c("year","scenario")) %>% 
  group_by(iteration, scenario, effort_data_weight) %>%
  summarise(rmse = sqrt(mean((value - f) ^ 2)),
            bias = median((value - f) / f)) %>%
  ungroup() %>%
  group_by(effort_data_weight) %>%
  mutate(mean_bias = mean(bias),
         mean_rmse = mean(rmse))  %>% 
  ungroup()

rmse_plot <- f_rmse_bias%>%
  ggplot() +
  geom_density(
    aes(rmse, fill = effort_data_weight),
    alpha = 0.5,
    color = NA,
    show.legend = F
  ) +
  geom_vline(aes(xintercept = 0), size = 1, linetype = 2) +
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = "RMSE") +
  theme(
    legend.position = "bottom",
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.margin = unit(c(.1, .1, .1, .1), "lines")
  ) + 
  facet_wrap(~scenario)


bias_plot <- f_rmse_bias %>%
  ggplot() +
  geom_density(
    aes(bias, fill = effort_data_weight),
    alpha = 0.5,
    color = NA,
    show.legend = F
  ) +
  geom_vline(aes(xintercept = 0), size = 1, linetype = 2) +
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = "Bias") +
  theme(
    legend.position = "bottom",
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.margin = unit(c(.1, .1, .1, .1), "lines")
  ) + 
  facet_wrap(~scenario)


  (f_performance_plot |
     (rmse_plot / bias_plot)) + plot_layout(ncol = 2, widths = c(2, 1))



```



all with the same fishus idealus 

Compare assessments under

no recruitment, constant f, equilibrium

stochastic, environmental, and structural economic noise

stochastic, environmental, and non-structural economic noise (pull from @Szuwalski)


## Broader performance stats

PCA/regression/machine learning style exploration of what drives RMSE/BIAS/whatever it is. 


## Application to PISCO data

show assessment results for PISCO data

# Discussion

Why is this the most groundbreaking thing ever

Highlight some commonly available economic data for places

Discuss in context of channel islands: what does predictive model say should be performance under those circumstances, relative to other assessment methods

recommend ensemble approach 

tease next steps, economic only model other kinds of models, etc. 

# Works Cited



